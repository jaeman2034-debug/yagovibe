import { useEffect, useState } from "react";
import { handleVoiceCommand } from "@/services/VoiceAgentCore";
import { useNavigate } from "react-router-dom";

// ğŸ¯ ìŒì„± ëª…ë ¹ + AI ì‘ë‹µ(TTS) í†µí•© í›…
export function useSpeechCommand() {
  const [listening, setListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [message, setMessage] = useState("");
  const navigate = useNavigate();

  // âœ… ìŒì„± ì¶œë ¥(TTS)
  const speak = (text: string) => {
    if (!text) return;
    const utter = new SpeechSynthesisUtterance(text);
    utter.lang = "ko-KR";
    utter.pitch = 1.1;
    utter.rate = 1.0;
    utter.volume = 1.0;
    window.speechSynthesis.cancel();
    window.speechSynthesis.speak(utter);
  };

  useEffect(() => {
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setMessage("âŒ ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.continuous = false;
    recognition.interimResults = false;

    recognition.onresult = async (e: any) => {
      const text = e.results[0][0].transcript.trim();
      setTranscript(text);
      setListening(false);
      console.log("ğŸ¤ ì¸ì‹ëœ ìŒì„±:", text);

      // NLU + ë¼ìš°í„° ì²˜ë¦¬
      const res = await handleVoiceCommand(navigate, text);
      console.log("ğŸ¤– AI ì‘ë‹µ:", res);
      setMessage(res);

      // âœ… TTSë¡œ ë§í•˜ê¸°
      speak(res);
    };

    recognition.onerror = (e: any) => {
      console.error("ğŸ¤ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", e);
      setMessage("ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      setListening(false);
    };

    if (listening) recognition.start();

    return () => recognition.stop();
  }, [listening, navigate]);

  return { listening, transcript, message, setListening };
}
