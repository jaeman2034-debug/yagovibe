# Step 45: ëŒ€ìš©ëŸ‰ ë¶„ì‚° íŒŒì´í”„ë¼ì¸ (Firestore â†’ Pub/Sub â†’ Dataflow â†’ BigQuery ìŠ¤íŠ¸ë¦¬ë°)

ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ë©°, íƒ„ë ¥ í™•ì¥, ì •í™•-í•œë²ˆ ì²˜ë¦¬(idempotent), ì´ˆ ë‹¨ìœ„ ì§€ì—° ìµœì†Œí™”ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.

## ğŸ“‹ ì•„í‚¤í…ì²˜

```
Firestore (qualityReports writes)
   â””â”€â”€ Functions Publisher (onWrite) â†’ Pub/Sub topic: yago-quality-events
                                    â†“
                           Dataflow (Apache Beam)
                              â†³ ë³€í™˜/ê²€ì¦/ì¤‘ë³µì œê±°/ìœˆë„ì‰
                              â†³ BigQuery Storage Write API â†’ yago_reports.quality_stream
                              â†³ (ì˜µì…˜) GCS raw backup
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: BigQuery í…Œì´ë¸” ìƒì„±

```bash
# BigQuery Consoleì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜
bq query --use_legacy_sql=false < scripts/create_bigquery_table.sql

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
bq mk --dataset yago_reports
bq mk --table \
  --time_partitioning_field event_ts \
  --clustering_fields team_id,report_id \
  yago_reports.quality_stream \
  scripts/create_bigquery_table.sql
```

### 2ë‹¨ê³„: Pub/Sub ë¦¬ì†ŒìŠ¤ ìƒì„±

```bash
export PROJECT_ID="your-project"
export REGION="asia-northeast3"

# í† í”½ ìƒì„±
gcloud pubsub topics create yago-quality-events \
  --project=$PROJECT_ID

# Dead Letter Queue í† í”½
gcloud pubsub topics create yago-quality-events-dlq \
  --project=$PROJECT_ID

# êµ¬ë… ìƒì„± (Dataflow ì „ìš©)
gcloud pubsub subscriptions create yago-quality-sub \
  --topic=yago-quality-events \
  --ack-deadline=60 \
  --dead-letter-topic=yago-quality-events-dlq \
  --dead-letter-max-delivery-attempts=10 \
  --project=$PROJECT_ID
```

### 3ë‹¨ê³„: Functions ë°°í¬

```bash
cd functions
npm install @google-cloud/pubsub
# ë˜ëŠ”
pnpm add @google-cloud/pubsub

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì )
firebase functions:config:set pubsub.topic="yago-quality-events"

# ë°°í¬
firebase deploy --only functions:publishQualityEvent
```

### 4ë‹¨ê³„: Dataflow íŒŒì´í”„ë¼ì¸ ë°°í¬

```bash
export PROJECT_ID="your-project"
export REGION="asia-northeast3"
export GCS_BUCKET="gs://your-bucket/dataflow"

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
python3 -m pip install -r dataflow/requirements.txt

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python3 dataflow/step45_stream.py \
  --project $PROJECT_ID \
  --region $REGION \
  --runner DataflowRunner \
  --staging_location $GCS_BUCKET/staging \
  --temp_location $GCS_BUCKET/temp \
  --input_subscription projects/$PROJECT_ID/subscriptions/yago-quality-sub \
  --bq_table yago_reports.quality_stream \
  --max_num_workers 10 \
  --num_workers 1
```

## ğŸ“Š ë°ì´í„° íë¦„

### 1. Firestore ì´ë²¤íŠ¸

```
teams/{teamId}/reports/{reportId}/qualityReports/{ts}
```

### 2. Functions Publisher

- ì´ë²¤íŠ¸ ê°ì§€
- ë©”íŠ¸ë¦­ ì¶”ì¶œ
- `insert_id` ìƒì„±: `${teamId}-${reportId}-${ts}`
- Pub/Sub ë©”ì‹œì§€ ë°œí–‰

### 3. Pub/Sub

- í† í”½: `yago-quality-events`
- êµ¬ë…: `yago-quality-sub`
- DLQ: `yago-quality-events-dlq`

### 4. Dataflow íŒŒì´í”„ë¼ì¸

1. **ReadFromPubSub**: Pub/Sub êµ¬ë…ì—ì„œ ë©”ì‹œì§€ ì½ê¸°
2. **ParseValidate**: JSON íŒŒì‹± ë° ê²€ì¦
3. **DedupInsertId**: insert_id ê¸°ë°˜ ì¤‘ë³µ ì œê±°
4. **WriteToBQ**: BigQuery Storage Write APIë¡œ ì“°ê¸°

### 5. BigQuery

- í…Œì´ë¸”: `yago_reports.quality_stream`
- íŒŒí‹°ì…˜: `DATE(event_ts)`
- í´ëŸ¬ìŠ¤í„°ë§: `team_id, report_id`

## ğŸ”§ ìš´ì˜ ê°€ë“œë ˆì¼

### ì •í™•-í•œë²ˆ ì²˜ë¦¬ (Idempotent)

1. **insert_id ê¸°ë°˜ ì¤‘ë³µ ì œê±°**
   - Functionsì—ì„œ ìƒì„±: `${teamId}-${reportId}-${ts}`
   - Dataflowì—ì„œ ë©”ëª¨ë¦¬ ìºì‹œë¡œ ì¤‘ë³µ ì œê±° (TTL 1ì‹œê°„)
   - BigQuery Storage Write APIì˜ insertId ê¸°ëŠ¥ í™œìš©

2. **ì¤‘ë³µ ì œê±° ì „ëµ**
   - ë©”ëª¨ë¦¬ ìºì‹œ (ì†Œê·œëª¨): í˜„ì¬ êµ¬í˜„
   - Redis/Spanner/Bigtable (ëŒ€ê·œëª¨): ìš´ì˜ í™˜ê²½ ê¶Œì¥

### DLQ ëª¨ë‹ˆí„°ë§

```bash
# DLQ ë©”ì‹œì§€ í™•ì¸
gcloud pubsub subscriptions pull yago-quality-events-dlq-sub \
  --project=$PROJECT_ID \
  --limit=10

# DLQ êµ¬ë… ìƒì„± (ëª¨ë‹ˆí„°ë§ìš©)
gcloud pubsub subscriptions create yago-quality-events-dlq-sub \
  --topic=yago-quality-events-dlq \
  --project=$PROJECT_ID
```

### Cloud Monitoring ì•Œë¦¼ ì„¤ì •

1. Cloud Console > Monitoring > Alerting
2. ìƒˆ ì •ì±… ìƒì„±
3. ë©”íŠ¸ë¦­: `pubsub.googleapis.com/subscription/num_undelivered_messages`
4. ì¡°ê±´: `yago-quality-sub` êµ¬ë…ì˜ ë¯¸ë°°ë‹¬ ë©”ì‹œì§€ > 100
5. ì•Œë¦¼ ì±„ë„: Email/Slack

### ìŠ¤í‚¤ë§ˆ ì§„í™”

ìƒˆë¡œìš´ í•„ë“œë¥¼ ì¶”ê°€í•  ë•Œ:

1. **BigQuery í…Œì´ë¸” ì—…ë°ì´íŠ¸**
   ```sql
   ALTER TABLE `yago_reports.quality_stream`
   ADD COLUMN new_field STRING;
   ```

2. **Beam ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸**
   ```python
   SCHEMA = {
       'fields': [
           # ... ê¸°ì¡´ í•„ë“œ
           {'name': 'new_field', 'type': 'STRING', 'mode': 'NULLABLE'},
       ]
   }
   ```

3. **Functions Publisher ì—…ë°ì´íŠ¸**
   ```typescript
   const payload = {
       // ... ê¸°ì¡´ í•„ë“œ
       new_field: value,
   };
   ```

4. **íŒŒì´í”„ë¼ì¸ ì¬ë°°í¬**

### ë¹„ìš© ë° ì„±ëŠ¥ ìµœì í™”

1. **ì›Œì»¤ ìˆ˜ ì¡°ì •**
   - ìµœì†Œ: 1ê°œ (ë¹„ìš© ì ˆê°)
   - ìµœëŒ€: 10ê°œ (ìë™ í™•ì¥)
   - ìë™ í™•ì¥ í™œì„±í™”

2. **ë©”ì‹œì§€ ì²˜ë¦¬ ì§€ì—°**
   - ëª©í‘œ: ì´ˆ ë‹¨ìœ„
   - ëª¨ë‹ˆí„°ë§: Pub/Sub ì§€ì—° ë©”íŠ¸ë¦­ í™•ì¸

3. **ë¹„ìš© ìµœì í™”**
   - ìµœì†Œ ì›Œì»¤ ìˆ˜ ì‚¬ìš©
   - ìë™ í™•ì¥ìœ¼ë¡œ íŠ¸ë˜í”½ì— ë”°ë¼ ì¡°ì •
   - GCS ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬

## ğŸ› ì¥ì•  ëŒ€ì‘ Runbook

### Pub/Sub DLQ ì ì¬ ì¦ê°€

**ì¦ìƒ**: DLQì— ë©”ì‹œì§€ê°€ ê³„ì† ìŒ“ì„

**ì›ì¸ ì§„ë‹¨**:
1. Functions ë¡œê·¸ í™•ì¸: `firebase functions:log --only publishQualityEvent`
2. ë©”ì‹œì§€ í˜ì´ë¡œë“œ í™•ì¸: DLQì—ì„œ ë©”ì‹œì§€ pullí•˜ì—¬ í™•ì¸
3. ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜ í™•ì¸

**í•´ê²° ë°©ë²•**:
- Functions ì½”ë“œ ì˜¤ë¥˜ ìˆ˜ì •
- ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸
- BigQuery ê¶Œí•œ í™•ì¸

### Dataflow ì›Œì»¤ ì—ëŸ¬ ì¦ê°€

**ì¦ìƒ**: ì›Œì»¤ê°€ ê³„ì† ì‹¤íŒ¨

**ì›ì¸ ì§„ë‹¨**:
1. Dataflow ë¡œê·¸ í™•ì¸: Cloud Console > Dataflow > Jobs > Logs
2. ìŠ¤í…Œì´ì§• ë²„í‚· ê¶Œí•œ í™•ì¸
3. ë„¤íŠ¸ì›Œí‚¹ í™•ì¸ (VPC, ë°©í™”ë²½)

**í•´ê²° ë°©ë²•**:
- GCS ë²„í‚· ê¶Œí•œ ìˆ˜ì •
- ë„¤íŠ¸ì›Œí¬ ì„¤ì • í™•ì¸
- ì›Œì»¤ ìˆ˜ ì¡°ì •

### BigQuery ì“°ê¸° ì˜¤ë¥˜

**ì¦ìƒ**: BigQueryì— ë°ì´í„°ê°€ ì“°ì´ì§€ ì•ŠìŒ

**ì›ì¸ ì§„ë‹¨**:
1. í…Œì´ë¸” ê¶Œí•œ í™•ì¸
2. ìŠ¤í‚¤ë§ˆ í™•ì¸
3. Storage Write API í• ë‹¹ëŸ‰ í™•ì¸

**í•´ê²° ë°©ë²•**:
- ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ ë¶€ì—¬
- ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸
- í• ë‹¹ëŸ‰ ì¦ê°€ ìš”ì²­

## ğŸ“¦ ë°±í•„ (Backfill) ë°°ì¹˜ ì¡

### ê¸°ì¡´ Firestore ë°ì´í„° Export

```bash
# ë°©ë²• 1: ìë™ ìŠ¤í¬ë¦½íŠ¸
bash scripts/export_firestore.sh

# ë°©ë²• 2: ìˆ˜ë™ ì‹¤í–‰
gcloud firestore export gs://your-bucket/firestore-export/TIMESTAMP \
  --collection-ids=teams \
  --project=$PROJECT_ID
```

### ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# ë°©ë²• 1: ìë™ ìŠ¤í¬ë¦½íŠ¸
export EXPORT_PATH="gs://your-bucket/firestore-export/20240101_120000"
bash scripts/backfill_step45.sh

# ë°©ë²• 2: ìˆ˜ë™ ì‹¤í–‰
python3 dataflow/step45_backfill.py \
  --project $PROJECT_ID \
  --region $REGION \
  --runner DataflowRunner \
  --staging_location $GCS_BUCKET/staging \
  --temp_location $GCS_BUCKET/temp \
  --input_pattern "gs://your-bucket/firestore-export/**/*qualityReports*.json" \
  --bq_table yago_reports.quality_stream \
  --max_num_workers 10 \
  --num_workers 2
```

### ë°±í•„ ê°€ì´ë“œ

ìì„¸í•œ ë‚´ìš©ì€ `Step45_ë°±í•„ê°€ì´ë“œ.md` ì°¸ì¡°

## ğŸ” ëª¨ë‹ˆí„°ë§

### Pub/Sub ë©”íŠ¸ë¦­

- `pubsub.googleapis.com/subscription/num_undelivered_messages`: ë¯¸ë°°ë‹¬ ë©”ì‹œì§€ ìˆ˜
- `pubsub.googleapis.com/subscription/oldest_unacked_message_age`: ê°€ì¥ ì˜¤ë˜ëœ ë¯¸í™•ì¸ ë©”ì‹œì§€ ë‚˜ì´

### Dataflow ë©”íŠ¸ë¦­

- `dataflow.googleapis.com/job/current_num_workers`: í˜„ì¬ ì›Œì»¤ ìˆ˜
- `dataflow.googleapis.com/job/elapsed_time`: ì‘ì—… ê²½ê³¼ ì‹œê°„
- `dataflow.googleapis.com/job/elements_produced_count`: ì²˜ë¦¬ëœ ìš”ì†Œ ìˆ˜

### BigQuery ë©”íŠ¸ë¦­

- `bigquery.googleapis.com/streaming/insert_row_count`: ìŠ¤íŠ¸ë¦¬ë° ì‚½ì… í–‰ ìˆ˜
- `bigquery.googleapis.com/streaming/insert_request_count`: ìŠ¤íŠ¸ë¦¬ë° ì‚½ì… ìš”ì²­ ìˆ˜

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„ (Step 46 ì˜ˆê³ )

- ì‹¤ì‹œê°„ ê·œì¹™ ì—”ì§„ + ì´ìƒ íƒì§€ (Anomaly Detection)
- Dataflowì— Sliding Window + Z-score/ESD ì ìš©
- ì„ê³„ì¹˜ ëŒ€ì‹  í†µê³„ì  ì´ìƒ ê°ì§€ë¡œ Slack ì•Œë¦¼/ìë™ í‹°ì¼“ ìƒì„± (Jira/Notion)

## ğŸ› ï¸ ìœ ìš©í•œ ëª…ë ¹ì–´

### Pub/Sub ë©”ì‹œì§€ ìˆ˜ë™ ë°œí–‰ (í…ŒìŠ¤íŠ¸)

```bash
echo '{"insert_id":"test-1","team_id":"TEST","report_id":"test-report","event_ts":"2024-01-01T00:00:00Z","overallScore":0.95,"coverage":0.98,"gaps":0,"overlaps":0,"avgDur":2.5,"source":"stream"}' | \
gcloud pubsub topics publish yago-quality-events \
  --project=$PROJECT_ID
```

### Dataflow ì‘ì—… ìƒíƒœ í™•ì¸

```bash
gcloud dataflow jobs list \
  --project=$PROJECT_ID \
  --region=$REGION \
  --status=active
```

### BigQuery ë°ì´í„° í™•ì¸

```sql
-- ìµœê·¼ 24ì‹œê°„ ë°ì´í„°
SELECT * FROM `yago_reports.quality_stream_recent`
ORDER BY event_ts DESC
LIMIT 100;

-- íŒ€ë³„ ì§‘ê³„
SELECT * FROM `yago_reports.quality_stream_team_summary`
ORDER BY team_id, date DESC;
```

